{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "카카오페이지 관련 트위터 텍스트 분석.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOIZizxjkOkQnNMS98vOCYg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Eunjung-Cho/Project/blob/master/webnovel/%EC%B9%B4%EC%B9%B4%EC%98%A4%ED%8E%98%EC%9D%B4%EC%A7%80_%EA%B4%80%EB%A0%A8_%ED%8A%B8%EC%9C%84%ED%84%B0_%ED%85%8D%EC%8A%A4%ED%8A%B8_%EB%B6%84%EC%84%9D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCDMI5x9nW3d"
      },
      "source": [
        "# 필요한 라이브러리\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-b1GB12oD3-"
      },
      "source": [
        "!pip install tweepy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVixFo48gpyO"
      },
      "source": [
        "# 패키지 설치 확인\n",
        "import tweepy"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsLn_Db0nctV"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-siiI11Pg0xm"
      },
      "source": [
        "주피터노트북으로 할 경우 pip install beautifulsoup4, pip install lxml 하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pX_oyzPhhDp_"
      },
      "source": [
        "#### api 토큰 인증"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2NDEKn-g8FN"
      },
      "source": [
        "# 발급 완료된 키 입력하기\n",
        "CONSUMER_KEY = \"api요청받은 키 입력하기\"\n",
        "CONSUMER_SECRET =\"api요청받은 키 입력하기\"\n",
        "ACCESS_TOKEN_KEY = \"api요청받은 키 입력하기\"\n",
        "ACCESS_TOKEN_SECRET = \"api요청받은 키 입력하기\"\n",
        "\n",
        "#개인정보 인증을 요청하는 Handler\n",
        "auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
        "\n",
        "#인증 요청 수락하기\n",
        "auth.set_access_token(ACCESS_TOKEN_KEY, ACCESS_TOKEN_SECRET)\n",
        "\n",
        "# 트위터 API를 사용하기 위한 준비\n",
        "api = tweepy.API(auth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joGf1tOam22F"
      },
      "source": [
        "# 크롤링하고 싶은 키워드 입력하기\n",
        "keyword = \"카카오 페이지\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6oCAfYInALj"
      },
      "source": [
        "tweets = api.search(keyword)\n",
        "for tweet in tweets:\n",
        "    print(tweet.text)\n",
        "    print(tweet.entities['user_mentions'])\n",
        "    print(tweet.entities['hashtags'])\n",
        "    print(tweet.created_at)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjfG7ParnWGS"
      },
      "source": [
        "### 데이터 프레임 형태로 수집"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rl1uzwCinVvO"
      },
      "source": [
        "# 크롤링된 데이터를 저장할 데이터 프레임입니다.\n",
        "columns = ['created', 'tweet_text']\n",
        "df = pd.DataFrame(columns=columns)\n",
        "\n",
        "# 크롤링을 수행할 갯수(여기서는 1000개)를 입력하고, Cursor 객체를 사용하여 크롤링을 수행합니다.\n",
        "max_tweets = 1000\n",
        "searched_tweets = [status for status in tweepy.Cursor(api.search, q=keyword).items(max_tweets)]\n",
        "\n",
        "# ‘카카오 페이지’가 포함된 1000개의 트윗들에서, ‘text’, ‘created_at’ 정보를 데이터 프레임으로 저장합니다.\n",
        "for tweet in searched_tweets:\n",
        "    tweet_json = tweet._json\n",
        "    tweet_text = tweet_json['text']\n",
        "    created = tweet_json['created_at']\n",
        "    row = [created, tweet_text]\n",
        "    series = pd.Series(row, index=df.columns)\n",
        "    df = df.append(series, ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBTp8rOBoVL8"
      },
      "source": [
        "# 위의 데이터를 csv 로 저장\n",
        "df.to_csv(\"tweet_temp.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6Tyexzxoa4m"
      },
      "source": [
        "# 키워드 추출 하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0UIGJ7voeZI"
      },
      "source": [
        "## 텍스트 데이터 전처리 하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bC2TWKCqoam-"
      },
      "source": [
        "df = pd.read_csv(\"tweet_temp.csv\")\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKCxXDFjohu2"
      },
      "source": [
        "import re\n",
        "\n",
        "# 텍스트 정제 함수 : 한글 이외의 문자는 전부 제거합니다.\n",
        "def text_cleaning(text):\n",
        "    hangul = re.compile('[^ ㄱ-ㅣ가-힣]+') # 한글의 정규표현식을 나타냅니다.\n",
        "    result = hangul.sub('', text)\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzdVlYwxokXc"
      },
      "source": [
        "# ‘tweet_text’ 피처에 이를 적용합니다.\n",
        "df['ko_text'] = df['tweet_text'].apply(lambda x: text_cleaning(x))\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCaR6IysomCF"
      },
      "source": [
        "## konlpy 를 이용한 키워드 추출 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAMH-1xFolt0"
      },
      "source": [
        "from konlpy.tag import Okt\n",
        "from collections import Counter\n",
        "\n",
        "# 한국어 약식 불용어사전 예시 파일입니다. 출처 - (https://www.ranks.nl/stopwords/korean)\n",
        "korean_stopwords_path = \"../data/korean_stopwords.txt\"\n",
        "with open(korean_stopwords_path, encoding='utf8') as f:\n",
        "    stopwords = f.readlines()\n",
        "stopwords = [x.strip() for x in stopwords]\n",
        "\n",
        "def get_nouns(x):\n",
        "    nouns_tagger = Okt()\n",
        "    nouns = nouns_tagger.nouns(x)\n",
        "    \n",
        "    # 한글자 키워드를 제거합니다.\n",
        "    nouns = [noun for noun in nouns if len(noun) > 1]\n",
        "    \n",
        "    # 불용어를 제거합니다.\n",
        "    nouns = [noun for noun in nouns if noun not in stopwords]\n",
        "    \n",
        "    return nouns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cODRTT1Dor5z"
      },
      "source": [
        "# ‘ko_text’ 피처에 이를 적용합니다.\n",
        "df['nouns'] = df['ko_text'].apply(lambda x: get_nouns(x))\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qmz1uB2Hotyn"
      },
      "source": [
        "# 연관 분석석을 이용한 키워드 분석"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAhKjCLrovun"
      },
      "source": [
        "!pip install apriori apyori"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEa96gOTo1r-"
      },
      "source": [
        "from apyori import apriori\n",
        "\n",
        "# 장바구니 형태의 데이터(트랜잭션 데이터)를 생성합니다.\n",
        "transactions = [\n",
        "    ['카카오페이지', '로판'],\n",
        "    ['카카오페이지', '로맨스'],\n",
        "    ['카카오페이지', '로판', '로맨스판타지']\n",
        "]\n",
        "\n",
        "# 연관 분석을 수행합니다.\n",
        "results = list(apriori(transactions))\n",
        "for result in results:\n",
        "    print(result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3efhH1WpBFf"
      },
      "source": [
        "# 지지도 0.5, 신뢰도 0.6, 향상도 1.0 이상이면서 (카카오페이지, ?) 처럼 규칙의 크기가 2 이하인 규칙을 추출합니다.\n",
        "list(apriori(transactions,\n",
        "             min_support=0.5,\n",
        "             min_confidence=0.6,\n",
        "             min_lift=1.0,\n",
        "             max_length=2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bvfr8A6IpFa_"
      },
      "source": [
        "## 트위터 연관 키워드 분석"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ju0qk5SHpH8X"
      },
      "source": [
        "# 트랜잭션 데이터를 추출합니다.\n",
        "transactions = df['nouns'].tolist()\n",
        "transactions = [transaction for transaction in transactions if transaction] # 공백 문자열을 방지합니다.\n",
        "print(transactions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEXtvrpfpJuB"
      },
      "source": [
        "# 연관 분석을 수행합니다.\n",
        "results = list(apriori(transactions,\n",
        "                       min_support=0.05,\n",
        "                       min_confidence=0.1,\n",
        "                       min_lift=5,\n",
        "                       max_length=2))\n",
        "print(results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p02doUFNpM9V"
      },
      "source": [
        "\n",
        "# 데이터 프레임 형태로 정리합니다.\n",
        "columns = ['source', 'target', 'support']\n",
        "network_df = pd.DataFrame(columns=columns)\n",
        "\n",
        "# 규칙의 조건절을 source, 결과절을 target, 지지도를 support 라는 데이터 프레임의 피처로 변환합니다.\n",
        "for result in results:\n",
        "    if len(result.items) == 2:\n",
        "        items = [x for x in result.items]\n",
        "        row = [items[0], items[1], result.support]\n",
        "        series = pd.Series(row, index=network_df.columns)\n",
        "        network_df = network_df.append(series, ignore_index=True)\n",
        "\n",
        "network_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7OpDRoCpOGT"
      },
      "source": [
        "# 단어 빈도 추출하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-ZrU7aIpPeX"
      },
      "source": [
        "## 말뭉치 추출"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODlqqrq-pQrV"
      },
      "source": [
        "# 말뭉치를 추출합니다.\n",
        "tweet_corpus = \"\".join(df['ko_text'].tolist())\n",
        "print(tweet_corpus)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVI0PXaRpSyZ"
      },
      "source": [
        "from konlpy.tag import Okt\n",
        "from collections import Counter\n",
        "\n",
        "# 명사 키워드를 추출합니다.\n",
        "nouns_tagger = Okt()\n",
        "nouns = nouns_tagger.nouns(tweet_corpus)\n",
        "count = Counter(nouns)\n",
        "\n",
        "# 한글자 키워드를 제거합니다.\n",
        "remove_char_counter = Counter({x : count[x] for x in count if len(x) > 1})\n",
        "print(remove_char_counter)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFtsQJ_BpVbu"
      },
      "source": [
        "## 단어빈도점수 추가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ac2IUjvipVTk"
      },
      "source": [
        "# 키워드와 키워드 빈도 점수를 ‘node’, ‘nodesize’ 라는 데이터 프레임의 피처로 생성합니다.\n",
        "node_df = pd.DataFrame(remove_char_counter.items(), columns=['node', 'nodesize'])\n",
        "node_df = node_df[node_df['nodesize'] >= 50] # 시각화의 편의를 위해 ‘nodesize’ 50 이하는 제거합니다.\n",
        "node_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWhNOwESpYDQ"
      },
      "source": [
        "# 시각화: 연관 키워드 네트워크 시각화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eW7EcJGpa5f"
      },
      "source": [
        "!pip install networkx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNrTkf2-pbnj"
      },
      "source": [
        "import networkx as nx\n",
        "plt.figure(figsize=(25,25))\n",
        "\n",
        "# networkx 그래프 객체를 생성합니다.\n",
        "G = nx.Graph()\n",
        "\n",
        "# node_df의 키워드 빈도수를 데이터로 하여, 네트워크 그래프의 ‘노드’ 역할을 하는 원을 생성합니다.\n",
        "for index, row in node_df.iterrows():\n",
        "    G.add_node(row['node'], nodesize=row['nodesize'])\n",
        "    \n",
        "# network_df의 연관 분석 데이터를 기반으로, 네트워크 그래프의 ‘관계’ 역할을 하는 선을 생성합니다.\n",
        "for index, row in network_df.iterrows():\n",
        "    G.add_weighted_edges_from([(row['source'], row['target'], row['support'])])\n",
        "    \n",
        "# 그래프 디자인과 관련된 파라미터를 설정합니다.\n",
        "pos = nx.spring_layout(G, k=0.6, iterations=50)\n",
        "sizes = [G.nodes[node]['nodesize']*25 for node in G]\n",
        "nx.draw(G, pos=pos, node_size=sizes)\n",
        "\n",
        "# Windows 사용자는 AppleGothic 대신,'Malgun Gothic'. 그 외 OS는 OS에서 한글을 지원하는 기본 폰트를 입력합니다.\n",
        "nx.draw_networkx_labels(G, pos=pos, font_family='AppleGothic', font_size=25)\n",
        "\n",
        "# 그래프를 출력합니다.\n",
        "ax = plt.gca()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}